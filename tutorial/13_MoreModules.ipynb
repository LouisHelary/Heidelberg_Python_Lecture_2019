{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on modules\n",
    "\n",
    "## 1) NumPy:\n",
    "\n",
    "NumPy is one of the module that is very useful for data-analysis as it allows to manipulate vectors, matrix and arrays. All the elements of each of these can be access one by one, or treated together.\n",
    "\n",
    "NumPy is loaded like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #not necessary to call the alias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Array:\n",
    "\n",
    "They corresponds to tables with one or more dimensions, and can be used to perform vectorial computation. The array() function allow to convert a list or a tuple into an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=[1,2,3]\n",
    "np.array(a)\n",
    "b=np.array(a)\n",
    "print(b)\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An array only contain data from a same type. It is possible to create an array from a list containing integers and strings of characters, but in this case all the values will be understood by NumPy as characters. It is also possible to create an array from a list containing both integer and floats, but in this case they will all be considered as float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"list with integer and strings:\")\n",
    "a = np. array ([1 , 2, \"tiger\"])\n",
    "print(a)\n",
    "type(a)\n",
    "\n",
    "print(\"list with integer and floats:\")\n",
    "b = np. array ([1 , 2, 3.4])\n",
    "print(b)\n",
    "type(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way as the range() function, the arange() function allow to contruct a 1D array very simply. It is also possible to specify a beginning, an end, and a step. And depending on the type passed it will construct the table accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Integer array [0-9]: \",np.arange (10))\n",
    "\n",
    "print(\"Integer array [10,1]:\",np.arange (10 , 0, -1))\n",
    "\n",
    "print(\"Integer array, type of 1 element: \",type(np.arange (10)[0]))\n",
    "\n",
    "print(\"Float array, type of 1 element: \",type(np. arange (10.)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between an array object and a list (or tuple) is that it is considered as a vector. It is therefore possible to perform vectorial operation on its elements. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np. arange (4)\n",
    "print(\"v: \",v)\n",
    "print(\"v+1: \",v+1)\n",
    "print(\"v+0.1: \",v+0.11)\n",
    "print(\"v*2: \",v*2)\n",
    "print(\"v*v: \",v*v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wanted to perform such operation with lists, it would have been mandatory to use loops. It is much easier (and faster) to perform these operations using arrays! In the final example \"v\\*v\" the operation correspond to the multiplication element by element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) multi-dimension array:\n",
    "    \n",
    "It is also possible to construct n-dimensions array, in which case one just need to provide a n-dimension list to the array() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np. array ([[1 ,2] ,[3 ,4] ,[5 ,6]])\n",
    "print(\"2D array \",w)\n",
    "\n",
    "ww= np. array ([[[1 ,2] ,[2 ,3]] ,[[4 ,5] ,[5 ,6]]])\n",
    "print(\"3D array \",w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2 dimensional array is considered to be a matrix. There are a few attribute that allow to retrieve information on an array dimensions:\n",
    "- ndim: return the number of dimensions.\n",
    "- shape: return the dimensions as a tuple.\n",
    "- size: return the total amount of elements in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np. arange (4)\n",
    "print(\"1D array: \",v)\n",
    "print(\"ndim: \",v.ndim)\n",
    "print(\"shape: \",v.shape)\n",
    "print(\"size: \",v.size)\n",
    "\n",
    "w = np. array ([[1 ,2] ,[3 ,4] ,[5 ,6]])\n",
    "print(\"2D array: \",w)\n",
    "print(\"ndim: \",w.ndim)\n",
    "print(\"shape: \",w.shape)\n",
    "print(\"size: \",w.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reshape method allow to modify the dimensions of an array. Since we are doing matrix manipulation, the order matter! If one try to call the reshape method with an incompatible number of dimension, one get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange (0, 6)\n",
    "print(\"1D array: \",a)\n",
    "print(\"shape: \",a.shape)\n",
    "b = a. reshape ((2 , 3))\n",
    "print(\"2D array with reshape(2,3): \",b)\n",
    "print(\"shape: \",b.shape)\n",
    "\n",
    "c = a. reshape ((3 , 2))\n",
    "print(\"2D array with reshape(3,2): \",c)\n",
    "print(\"shape: \",c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use the resize() method to do an equivalent action, but with resize(), if the number of dimension entered is not compatible with the dimensions used in the array, the extra dimension will be filled with 0s instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np. arange (0, 6)\n",
    "print(a. shape)\n",
    "a. resize ((3 , 3))\n",
    "print(a. shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is also the np.resize() function which will repeat the original array if the dimension is greater than the original:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np. arange (0, 6)\n",
    "print(a. shape)\n",
    "c = np. resize (a, (3, 5))\n",
    "print(c. shape)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Indices:\n",
    "\n",
    "To retrieve one or multiple elements from an array, one can use the indices as for the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np. arange (10)\n",
    "print(a)\n",
    "print(a[5:])\n",
    "print(a [::2])\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can modify elements in an array using it's index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange (10)\n",
    "print(a)\n",
    "a[2]=30\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a multi-dimensional array, one can retrieve a full list (index m), a column (index n), or a single element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np. array ([[1 ,2] ,[3 ,4]])\n",
    "print(a)\n",
    "print(a[: ,0])\n",
    "print(a[0 ,:])\n",
    "print(a[1 ,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the a[m,:] will return the line m-1 while a[:,n] will return the column n-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Automatic construction of a matrix:\n",
    "\n",
    "The functions zeros() and ones(), will construct matrices filled with 0s and 1s. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2*3 matrix: \\n\",np. zeros ((2 , 3)))\n",
    "print(\"3*3 matrix: \\n\",np. zeros ((3 , 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the zeros() and ones() functions return float but it is possible to instentiate with integers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np. zeros ((2 ,3) , int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use the full function to instentiate a matrix with something else than 0s or 1s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np. full ((2 , 3), 7, int ))\n",
    "print(np. full ((2 , 3), 7, float ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Linear algebra:\n",
    "\n",
    "It is possible to do linear algebra operations. The transpose() function return the transposed matrixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np. resize (np. arange (1, 10) , (3, 3))\n",
    "print(a)\n",
    "np.transpose(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot() function will return the matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np. resize (np. arange (4) , (2, 2))\n",
    "print(a)\n",
    "np.dot(a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to perform more operations linear operations using the linalg submodule: matrix inversion, calculation of the determinant or the eigen values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np. resize (np. arange (4) , (2 ,2))\n",
    "print(a)\n",
    "\n",
    "print(np.linalg.inv(a))\n",
    "print(np.linalg.det(a))\n",
    "print(np.linalg.eig(a))\n",
    "print(np.linalg.eig(a)[0])\n",
    "print(np.linalg.eig(a)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) matplotlib:\n",
    "\n",
    "### 2.1) First plots:\n",
    "\n",
    "This module allow to generate graphics in Python. It is complementary to NumPy, scipy or pandas for data analysis.\n",
    "\n",
    "Let's consider the evolution of alcool in the blood as a function of time. One get the following results that we want to plot:\n",
    "\n",
    "| time | concentration |\n",
    "| ----| --- |\n",
    "| 1| 3.5|\n",
    "| 2| 5.8|\n",
    "| 3| 9.1|\n",
    "| 4| 11.8|\n",
    "| 6| 17.5|\n",
    "| 7| 21.3|\n",
    "| 9| 26.8|\n",
    "\n",
    "This is done following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib . pyplot as plt\n",
    "time = [1, 2, 3, 4, 6, 7, 9]\n",
    "concentration = [5.5 , 7.2 , 11.8 , 13.6 , 19.1 , 21.7 , 29.4]\n",
    "plt.scatter(time , concentration , marker =\"o\", color =\"blue\")\n",
    "plt.xlabel(\" Time (h)\")\n",
    "plt.ylabel(\" Concentration (mg/L )\")\n",
    "plt.title(\" Product concentration as a function of time \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real shell environment it is possible to manipulate the picture, zoom, save, etc..\n",
    "\n",
    "Now let's see what we did step by step:\n",
    "- Import the module.\n",
    "- Define two lists that will be used to plot the different values.\n",
    "- Use the scatter() function to represent the points in a scatter plot.\n",
    "- Define the labels of both x and y axes.\n",
    "- Define the title.\n",
    "- Show the graphic to the screen.\n",
    "\n",
    "It is also possible to show a function near the data points. For instance in the previous case, one know that the concentration can be modelled using a function: $f(x)=2+3 \\times x$. Let's add it in the graph and save the picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib . pyplot as plt\n",
    "time = [1, 2, 3, 4, 6, 7, 9]\n",
    "concentration = [5.5 , 7.2 , 11.8 , 13.6 , 19.1 , 21.7 , 29.4]\n",
    "plt.scatter(time , concentration , marker =\"o\", color =\"blue\")\n",
    "plt.xlabel(\" Time (h)\")\n",
    "plt.ylabel(\" Concentration (mg/L )\")\n",
    "plt.title(\" Product concentration as a function of time \")\n",
    "x = np. linspace (min ( time ), max( time ), 50)\n",
    "y = 2 + 3 * x\n",
    "plt.plot(x, y, color ='green', ls =\"--\")\n",
    "plt.grid()\n",
    "plt.savefig('figures/concentration_vs_time.png', bbox_inches ='tight', dpi =200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to what we have done before:\n",
    "- One create a linspace variable using NumPy and instentiate the x array.\n",
    "- One construct the y variable from the x variable.\n",
    "- The plot() function allows to construct the curve from the coordinates given before. As for the scatter function, the plot and type of marker are not mandatory\n",
    "- The grid() function display a grid.\n",
    "- We save the plot using the savefig() function in the figures directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Drawing histograms:\n",
    "\n",
    "Matplotlib allows to easily generate histograms:\n",
    "For instance, let's plot the numbers in the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib . pyplot as plt\n",
    "\n",
    "data=[1,2,3,2,4,5,2,5,6,3,6,6,7,3,2,4]\n",
    "\n",
    "axe=range(10)\n",
    "distribution = []\n",
    "for item in axe :\n",
    "    distribution.append(data.count(item))\n",
    "    \n",
    "x = np.arange(len(axe))\n",
    "plt.bar(x, distribution )\n",
    "plt.xticks(x, axe )\n",
    "plt.xlabel(\"Number\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"First Histogram\")\n",
    "plt.savefig ('figures/histogram.png', bbox_inches =\"tight\", dpi =200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go in detail in what was done:\n",
    "- define the data we want to count the number of each iteration. Then define the number we want to count (axis).\n",
    "- count the number of occurence of each number in the data list.\n",
    "- define the position of the axis ticks.\n",
    "- construct the histogram with the bar() function.\n",
    "- construct the x axis wit the xtics() function.\n",
    "- define the legends and the title.\n",
    "- save the histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Pandas:\n",
    "### 3.1) Series:\n",
    "The pandas module is useful to manipulate data that are structure under the form of tables. To load pandas in Python one need to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # As usual the alias is not formally needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first type of data structure used in pandas is a series, which correspond to a vector with 1 dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10 , 20, 30, 40],index=['a', 'b', 'c', 'd'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pandas each element in the series has a unique label, that allow to call it. For example to get the first element of the series we can either use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Print element using index: \",s[0])\n",
    "print(\"Print element using label a: \",s[\"a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to extract multiple elements using their index or label, and one can use these to modify or add the content of the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s [[1 ,3]])\n",
    "print(s [[\"b\",\"d\"]])\n",
    "s[\"c\"] = 300\n",
    "s[\"z\"] = 50\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to filtrate a part of the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s[s >30])\n",
    "print(s[(s>20) & (s<100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Dataframes:\n",
    "#### 3.2.1) Introduction:\n",
    "Another type of object used in pandas are the dataframes, that corresponds to two-dimensional tables with labels for the lines and columns. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd. DataFrame ( columns =[\"a\", \"b\", \"c\", \"d\"], index =[\"cat\", \"mouse\", \"dog\"], data =[ np. arange (10 , 14) ,np. arange (20 , 24) ,np. arange (30 , 34)])\n",
    "print(df)\n",
    "\n",
    "df = pd. DataFrame ( \n",
    "    columns =[\"a\", \"b\", \"c\", \"d\"], \n",
    "    index =[\"cat\", \"mouse\", \"dog\"], \n",
    "    data =[ np. arange (10 , 14) ,\n",
    "           np. arange (20 , 24) ,\n",
    "           np. arange (30 , 34)])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these arguments can be put on a single line for more readability. \n",
    "\n",
    "The dataframe is created using the DataFrame() function that takes multiple arguments as input. \n",
    "- columns gives a label to each column.\n",
    "- index gives a label to each line.\n",
    "- data gives the content of the dataframe using lists corresponding to each lines. \n",
    "\n",
    "It is also possible to create the same dataframe using dictionnaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"a\": np. arange (10 , 40, 10) ,\n",
    "        \"b\": np. arange (11 , 40, 10) ,\n",
    "        \"c\": np. arange (12 , 40, 10) ,\n",
    "        \"d\": np. arange (13 , 40, 10)}\n",
    "df = pd. DataFrame . from_dict ( data )\n",
    "df. index = [\"cat\", \"mouse \", \"dog\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the data dictionnary contains the data in each column. The key associated to each column corresponds to name of the column.\n",
    "The dataframe is created using the pd.DataFrame.from_dict() function that uses data as an argument.\n",
    "One can define the labels of each dataframe line using df.index .\n",
    "\n",
    "#### 3.2.2) Properties:\n",
    "\n",
    "Dataframes have some properties:\n",
    " - .shape: return the dimensions of the dataframe.\n",
    " - .columns: return the name of the columns but also allow to rename the columns.\n",
    " - .head(n): functio that return the n first lines of the dataframe, by default it is equal to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape\",df.shape)\n",
    "print(\"columns\",df.columns)\n",
    "df.columns = [\"type1\", \"type2\", \"type3\", \"type4\"]\n",
    "print(df)\n",
    "df. head (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3) Selection:\n",
    "\n",
    "Pandas allow to select data from the dataframe. For instance one can select datas in one or more columns, or lines (using the .loc() instruction is one want to access it through the label, or the .iloc instruction from the line number):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"select 1 col:\",df[\"type1\"])\n",
    "print(\"\\nselect 2 col:\",df[[\"type1\",\"type2\"]])\n",
    "\n",
    "print(\"\\nselect 1 line using loc:\",df.loc[[\"cat\"]])\n",
    "print(\"\\nselect 2 line using loc:\",df.loc[[\"cat\",\"dog\"]])\n",
    "\n",
    "print(\"\\nselect 1 line using iloc:\",df.iloc[1])\n",
    "print(\"\\nselect 2 line using iloc:\",df.iloc[[1,0]])\n",
    "print(\"\\nselect 2 line using iloc:\",df.iloc[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to combine the two types of selections (using the lines and column). If one want to select lines one need to use loc or iloc with the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"type1\": np. arange (10 , 40, 10) ,\n",
    "        \"type2\": np. arange (11 , 40, 10) ,\n",
    "        \"type3\": np. arange (12 , 40, 10) ,\n",
    "        \"type4\": np. arange (13 , 40, 10)}\n",
    "df = pd. DataFrame . from_dict ( data )\n",
    "df. index = [\"cat\", \"mouse\", \"dog\"]\n",
    "df\n",
    "\n",
    "print(df.loc[\"cat\",\"type1\"])\n",
    "print(df.loc [[\"cat\", \"dog\"], ['type1', 'type3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to select using conditions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"select all lines where type4>15\\n\",\n",
    "      df[ df [\"type4\"] >15 ])\n",
    "print(\"\\n\")\n",
    "print(\"select all lines where type4>15 and select only type3\\n\",\n",
    "      df[ df [\"type4\"] >15 ][\"type3\"])\n",
    "print(\"\\n\")\n",
    "print(\"select all ligns with type4>15 and type3>25\\n\",\n",
    "      df[ (df [\"type4\"] >15) & (df[\"type3\"] > 25)])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"select all ligns with type4>15 or type3>25\\n\",\n",
    "      df[ (df [\"type4\"] >15) | (df[\"type3\"] > 25)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4) Combinations:\n",
    "\n",
    "It is possible to combine together multiple dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\"type1\": [10 , 23, 17] , \"type2\": [3, 15, 20]}\n",
    "df1 = pd.DataFrame.from_dict ( data1 )\n",
    "df1.index = [\"cat\", \"dog\", \"mouse\"]\n",
    "print(df1)\n",
    "\n",
    "\n",
    "data2 = {\"type3\": [3, 9, 14] , \"type4\": [5, 10, 8]}\n",
    "df2 = pd.DataFrame.from_dict (data2)\n",
    "df2 . index = [\"cat\", \"dog\", \"rabbit\"]\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concatenation of the two dataframes is done using the .concat() function, that takes a list of dataframes as input and return a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ df1 , df2 ],sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous table we see multiple times: NaN meaning not a number, but we do not get the expected result since the lines have not been merger. This is done by using the axis=1 argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ df1 , df2 ],axis=1,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default pandas will show as much line as possible. One can also decide to only show the lines common to the two dataframes using the join=\"inner\" argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd. concat ([ df1 , df2], axis =1, join =\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) More concrete example:\n",
    "\n",
    "Let's look at a csv file that contains different variables separated by a comma (that's what CSV means..), import it in Python and analyse it.\n",
    "\n",
    "#### 3.3.1) Open the file:\n",
    "\n",
    "It is possible to easily open csv file and create pandas dataframe using the read_csv() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/Element_report.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file contains pseudo data, with 5 types of data contents:\n",
    "- ID: unique identifier.\n",
    "- Type: type of material.\n",
    "- Date: date of the sample.\n",
    "- Length: length of the sample.\n",
    "- Weight: weight of the sample.\n",
    "\n",
    "One can ask pandas to use a column as the index, which we will do with the ID one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Element_report.csv\",index_col =\"ID\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can take a look at its dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The element contain 41 lines and 4 columns, the ID is now use as an index. One can explore the different types of data in each columns. The object type is most of the time a string of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the date object is date that is always formatted the same in the csv file (year-month-day), one can ask pandas to interpret it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [\"Date\"] = pd. to_datetime (df [\"Date\"])\n",
    "print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2) Some statistics:\n",
    "\n",
    "For the data that contains numeric type, one can obtain some statistical information using the .describe() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df. describe ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the mean value, the standard deviation, the min and the max values. One can easily check the number of occurence of each types using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [\"Type\"]. value_counts ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each Type one can get the mean size and weight. The groupby() method, sort together all the equivalent types, then one get it's mean value using the mean() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Type\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to get more information using the .pivot_table() which is more complex but more powerful. In this function:\n",
    "- index corresponds to the column used to agregate the data.\n",
    "- values corresponds to the columns used to compute the stats.\n",
    "- aggfunc list the statistics computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df. pivot_table ( \n",
    "    index =\"Type\", \n",
    "    values =[\"Length\", \"Weight\"], \n",
    "    aggfunc =[ min , max ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3) Some plots:\n",
    "\n",
    "Let's plot the Weight as a function of it's size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df[\"Length\"], df[\"Weight\"])\n",
    "plt.xlabel(\"Size\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.savefig(\"figures/Weight_Size.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a nice correlation between the size of each sample and its weight. It is possible to zoom in on the left hand side group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz = df[df [\"Length\"] <400]\n",
    "plt.clf()\n",
    "plt.scatter(dfz [\"Length\"], dfz [\"Weight\"])\n",
    "plt.xlabel(\"Size\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.savefig(\"figures/Weight_Size2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it appears a clear correlation between the size and the weight, one can try to fit the two using a line, this is done using the scipy module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy. stats import linregress\n",
    "lr = linregress ( dfz [\"Length\"], dfz [\"Weight\"])\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(dfz [\"Length\"], dfz [\"Weight\"])\n",
    "plt.xlabel(\"Size\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.plot(dfz[\"Length\"], \n",
    "         dfz [\"Length\"]* lr. slope +lr. intercept , \n",
    "         ls =\":\")\n",
    "plt.savefig(\"figures/Weight_Size3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4) Analysis of the timing data:\n",
    "\n",
    "One can also analyse the time at which each sample has been discovered. The pivot_table() method already give us a first indication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df. pivot_table(\n",
    "    index =\"Type\", \n",
    "    values =[\"Date\"], \n",
    "    aggfunc =[ min , max ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wanted to know how many samples where discovered as a funtion of time, one could use the .value_counts() method. But it only returns counts for a single date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [\"Date\"]. value_counts (). head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one want an answer year by year one can use the .resample() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [\"Date\"]. value_counts (). resample (\"A\"). count ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to sort these directly using the .sort_values() method and limit the number of output using the head() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df [\"Date\"].value_counts().resample(\"A\").count().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Scipy:\n",
    "\n",
    "`scipy` is buildt on top of the `numpy` framework for multidimensional arrays, and provides a large number of higher-level scientific algorithms. Some of the topics that SciPy covers are:\n",
    "\n",
    "* Special functions ([scipy.special](http://docs.scipy.org/doc/scipy/reference/special.html))\n",
    "* Integration ([scipy.integrate](http://docs.scipy.org/doc/scipy/reference/integrate.html))\n",
    "* Optimization ([scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html))\n",
    "* Interpolation ([scipy.interpolate](http://docs.scipy.org/doc/scipy/reference/interpolate.html))\n",
    "* Fourier Transforms ([scipy.fftpack](http://docs.scipy.org/doc/scipy/reference/fftpack.html))\n",
    "* Signal Processing ([scipy.signal](http://docs.scipy.org/doc/scipy/reference/signal.html))\n",
    "* Linear Algebra ([scipy.linalg](http://docs.scipy.org/doc/scipy/reference/linalg.html))\n",
    "* Sparse Eigenvalue Problems ([scipy.sparse](http://docs.scipy.org/doc/scipy/reference/sparse.html))\n",
    "* Statistics ([scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html))\n",
    "* Multi-dimensional image processing ([scipy.ndimage](http://docs.scipy.org/doc/scipy/reference/ndimage.html))\n",
    "* File IO ([scipy.io](http://docs.scipy.org/doc/scipy/reference/io.html))\n",
    "\n",
    "Each of these submodules provides a number of functions and classes that can be used to solve problems in their respective topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Special functions\n",
    "Scipy implements a large amount of *special functions* (Bessel function,\n",
    "Airy function, orthogonal polynomials, ...) for numneric calculations. They can be used as functions within `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.special as ss\n",
    "\n",
    "# we plot the n\\in [1..3] Legendre polynomials.\n",
    "#\n",
    "x = np.linspace(-1.0, 1.0, 100)\n",
    "\n",
    "for n in range(1, 4):\n",
    "    y = ss.eval_legendre(n, x)\n",
    "    plt.plot(x, y, label=r\"$L_%d(x)$\" % n)\n",
    "    \n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Fitting:\n",
    "\n",
    "Determining a parametric model $y = m(x; a_0, a_1, \\dots a_n)$, where the $a_i$ are parameters we would like to determine) to given data points\n",
    "$(x_i; y_i \\pm \\Delta y_i);\\; i\\in [1, \\dots, m]$ is called *data-fitting*. Usually the measurements $y_i$ come with some errors $\\Delta y_i$. `Scipy` offers several functions for data fitting and I will show you the simplest one: `curve_fit`. It determines the best fit parameters with the $\\chi^2$-method, i.e. it determines best fit parameters by minimizing the expression:\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum_{i=1}^n\\frac{(y_i-m(x_i; a_0, a_1, \\dots a_n))^2}{(\\Delta y_i)^2}\n",
    "$$\n",
    "\n",
    "Please read the [curve_fit documentation](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit) on details (error handling etc.).\n",
    "\n",
    "For demonstration purposes we perform a line fit on some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import scipy.optimize as so\n",
    "\n",
    "# create some fake data and plot them:\n",
    "x = np.random.uniform(0., 100., 100)\n",
    "# The error on each point comes from a normal distribution\n",
    "# with sigma = 10\n",
    "y = 2. * x + 2.6 + np.random.normal(0., 10., 100)\n",
    "plt.errorbar(x, y, yerr=10, fmt=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# now perform the fit\n",
    "# Please read carefully the documentation to see how errors\n",
    "# are handled. In Physics we typically give absolute errors,\n",
    "# note relative ones!\n",
    "popt, pcov = so.curve_fit(fit_line, x, y,\n",
    "                          sigma = np.ones(len(x)) * 10,\n",
    "                          absolute_sigma=True)\n",
    "print(popt, pcov)\n",
    "print(\"a = %f +/- %f\" % (popt[0], np.sqrt(pcov[0][0])))\n",
    "print(\"b = %f +/- %f\" % (popt[1], np.sqrt(pcov[1][1])))\n",
    "\n",
    "x_fit = np.linspace(0.0, 100, 100)\n",
    "y_fit = fit_line(x_fit, *(popt))\n",
    "plt.errorbar(x, y, yerr=10, fmt=\".\")\n",
    "plt.plot(x_fit, y_fit, 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Exercices:\n",
    "\n",
    "- Numpy: \n",
    "    - Create a null vector of size 10\n",
    "    - Create a vector with values ranging from 10 to 49\n",
    "    - Create a 3x3 matrix with values ranging from 0 to 8\n",
    "    - Create a 3x3 identity matrix\n",
    "    - Multiply a 5x3 matrix by a 3x2 matrix (real matrix product)\n",
    "    \n",
    "- Matplotlib:\n",
    "    - Plot two or more lines with different styles\n",
    "    - Generate two random list of floats in the range [-1,1] with 1000 entries each and plot them using a scatter plot.\n",
    "    \n",
    "- Pandas:\n",
    "    - Generate a random list of 1000 floats in the range [-1,1] and generate another list of 1000 integer in the range [0,1000]. Use the integer as index, and built a pandas dataset using the list of floats. \n",
    "        - Compute the minimum, 25th percentile, median, 75th, and maximum.\n",
    "    - Compute the number of characters in each element of the following series: ser = pd.Series(['going', 'to', 'the ', 'university?'])\n",
    "    - Convert a series of date-strings to a timeseries: ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "    - Replace both diagonals of the following dataframe with 0 df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
